{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right; width: 30%; height: 30%;\" src=\"images/mongodb.jpg\" />\n",
    "# JADS Data Engineering: MongoDB Exercises\n",
    "\n",
    "In this exercise we will work with MongoDB and cover the following subjects:\n",
    "\n",
    "- Data model considerations\n",
    "- Data insertion\n",
    "- Simple queries\n",
    "- More complex aggregations\n",
    "\n",
    "The exercise will start by configuring the Jupyter environment and setting up a MongoDB in the cloud. Next we will download the dataset for this exercise and transform it to input that is suitable for Mongo. Finally we will insert this data, run some basic queries and some more complex aggregations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "First of all we need access to a running MongoDB instance. While running MongoDB as a local process for testing and development purposes is not very complicated we will make use of a \"Database-as-a-Service\" provider for this exercise: \n",
    "\n",
    "1. Open a separate tab/window in your browser and browse to [https://mlab.com](https://mlab.com)\n",
    "2. Sign up (for free) and log in to the service\n",
    "3. mLab provides a free sandbox tier that is ideal for development and prototyping. Create a new Single-node deployment using the 'Sandbox' plan. Name it whatever you like (NB: use Amazon's EU Ireland region).\n",
    "4. Create a user for the newly created database that you will use in this exercise\n",
    "\n",
    "Next, we need to setup the Python environment so that the [Python driver](https://docs.mongodb.com/ecosystem/drivers/python/) is available. Execute the next cell to install the driver package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! conda install -y pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can verify that pymongo is installed correctly and that we can access our mLab database. We will do that by building a connection and querying the available collections (note that for a new database this will only return some system collections). In the next cells you will need to add the MongoDB URI that is shown on the information overview page (browse to your deployment). Note that you will need to add your username and password to the URI string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# TODO replace the `< >` with values for your deployment\n",
    "db_URI = 'mongodb://<user>:<pass>@<host>.mlab.com:<port>/<dbname>' \n",
    "db_name = '<dbname>'\n",
    "\n",
    "client = MongoClient(db_URI)\n",
    "db = client[db_name]\n",
    "res = db.collection_names()\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything checks out proceed to the next section. Make sure that you have the [pymongo API documentation](http://api.mongodb.com/python/current/api/pymongo/) and the [pymongo tutorial](http://api.mongodb.com/python/current/tutorial.html) open in your browser so that you can reference it during the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset\n",
    "\n",
    "Today, we will be using the [MovieLens 100K Dataset][1-1], a dataset containing movie ratings from the [MovieLens](https://movielens.org) website.\n",
    "\n",
    "First, download and unzip the 100K dataset. You will only need to consider the following files from the archive:\n",
    "\n",
    " - u.data\n",
    " - u.item\n",
    " - u.genre\n",
    " - u.user\n",
    " - u.occupation\n",
    "\n",
    "[1-1]: http://grouplens.org/datasets/movielens/100k/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget -q http://files.grouplens.org/datasets/movielens/ml-100k.zip && unzip ml-100k.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MovieLens data was collected through the MovieLens web site (movielens.umn.edu) during the seven-month period from September 1997 through April 1998. The data set consists of:\n",
    "\n",
    "- 100,000 ratings (1-5) from 943 users on 1682 movies. \n",
    "- Each user has rated at least 20 movies. \n",
    "- Simple demographic info for the users (age, gender, occupation, zip)\n",
    "\n",
    "This data is organized in five files:\n",
    "\n",
    "- __u.data:__ The 100,000 ratings. Users and items are numbered consecutively from 1. The data is randomly ordered. This is a tab separated list of user id | item id | rating | timestamp. The time stamps are unix seconds since 1/1/1970 UTC   \n",
    "\n",
    "- __u.item:__ Information about the items (movies); this is a pipe separated list of movie id | movie title | release date | video release date | IMDb URL | unknown | Action | Adventure | Animation | Children's | Comedy | Crime | Documentary | Drama | Fantasy | Film-Noir | Horror | Musical | Mystery | Romance | Sci-Fi | Thriller | War | Western | The last 19 fields are the genres, a 1 indicates the movie is of that genre, a 0 indicates it is not; movies can be in several genres at once. The movie ids are the ones used in the u.data data set.\n",
    "\n",
    "- __u.genre:__ A list of the genres.\n",
    "\n",
    "- __u.user:__ Demographic information about the users; this is a pipe separated list of user id | age | gender | occupation | zip code The user ids are the ones used in the u.data data set.\n",
    "\n",
    "- __u.occupation:__ A list of the occupations.\n",
    "\n",
    "Print the first two records of each of the files to better understand the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"u.data:\"\n",
    "head -n 2 ml-100k/u.data\n",
    "echo \"\"\n",
    "\n",
    "echo \"u.item:\"\n",
    "head -n 2 ml-100k/u.item\n",
    "echo \"\"\n",
    "\n",
    "echo \"u.genre:\"\n",
    "head -n 2 ml-100k/u.genre\n",
    "echo \"\"\n",
    "\n",
    "echo \"u.user:\"\n",
    "head -n 2 ml-100k/u.user\n",
    "echo \"\"\n",
    "\n",
    "echo \"u.occupation:\"\n",
    "head -n 2 ml-100k/u.occupation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise I: data model\n",
    "\n",
    "If you consider the data in more detail and think about how they would fit in a (simple)Entity-Relationship model you would probably come up with something not unlike the following:\n",
    "\n",
    "- Strong entities: Movie (item) and user\n",
    "- Relationships: A user rates a movie\n",
    "\n",
    "Or graphically (some attributes intentionally left out):\n",
    "\n",
    "</br></br>\n",
    "<img style=\"width: 75%; height: 75%;\" src=\"images/simpleer3.png\" />\n",
    "</br></br>\n",
    "\n",
    "You might model the genre and occupation attributes as weak entities with a relationships. Translating this to a relational database model is rather trivial. \n",
    "\n",
    "For this first exercise think about how you would translate this model to the document store MongoDB. Think about the different possibilities of storing the information: from fully denormalized where each record stores all the data, concerning that record, to a more normalized approach with separate collections modelling separate 'entities'. \n",
    "\n",
    "__Assignment:__ Describe how you would translate the data to documents in a document store and what information your documents and collections will store. Describe the pros and cons of your approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: ADD YOUR DESCRIPTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise IIa: Loading the data in MongoDB\n",
    "\n",
    "Now you will have to provide functionality to load the datafiles into Mongo. First you will have to engage in the less sexy part of data science and convert the MovieLens data to collections of JSON documents to insert in Mongo. Consider the following user and item examples:\n",
    "\n",
    "    {\n",
    "        \"id\": 474\n",
    "        \"title\": \"Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)\",\n",
    "        \"release_date\": \"01-Jan-1963\",\n",
    "        \"genres\": [\n",
    "            \"Sci-Fi\",\n",
    "            \"War\"\n",
    "        ]\n",
    "    }\n",
    "     \n",
    "    {\n",
    "        \"id\": 73\n",
    "        \"age\": 24,\n",
    "        \"gender\": \"M\",\n",
    "        \"occupation\": \"student\",\n",
    "        \"zip\": \"41850\"\n",
    "    }\n",
    "\n",
    "If you don't know how to approach this, use the following hint:\n",
    "\n",
    "Gur rnfvrfg nccebnpu vf gb ernq va gur hfre naq vgrz qngn va zrzbel. Perngr gjb ybbxhc gnoyrf (unfuznc be qvpgvbanel). Arkg ernq va gur engvatf naq hfr gur ybbxhc gnoyrf gb bhgchg qrabeznyvfrq qngn, ntnva va n yvfg be qvpg.\n",
    "\n",
    "As a convenience we have already provided a genre lists you can use in your function(s). If, after half an hour you are still stuck with this call for help.\n",
    "\n",
    "__Assignment:__ Write functions to convert the files to collections of dicts. Create these collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO Convert the data files to collections of JSON records (dicts in Python will do).\n",
    "\n",
    "genre_list = [\"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children's\",\n",
    "              \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\",\n",
    "              \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\",\n",
    "              \"War\", \"Western\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise IIb: Loading the data in MongoDB\n",
    "\n",
    "MongoDB supports bulk writes; read the pymongo documentation of the [`bulk_write`](http://api.mongodb.com/python/current/api/pymongo/collection.html#pymongo.collection.Collection.bulk_write) function to see how the function is called. Use the collections you created in exercise IIa to insert the data in MongoDB. You can reuse the db object from the initial setup.\n",
    "\n",
    "Once the data is in demonstrate this by selecting one item from each of the collections you created. You can use the \n",
    "[`find`](http://api.mongodb.com/python/current/api/pymongo/collection.html#pymongo.collection.Collection.find) or [`find_one`](http://api.mongodb.com/python/current/api/pymongo/collection.html#pymongo.collection.Collection.find_one) functions for this.\n",
    "\n",
    "__Assignment:__ Bulk insert the collections you created. Demonstrate by selecting one item from each of the document types or collections you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO Load your collections of dicts into your mLab MongoDB deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise III: Queries and aggregations\n",
    "\n",
    "Once the data is imported you can use the MongoDB data manipulation commands to browse your database. Try some simple queries first and then write and perform queries that answer the following questions:\n",
    "\n",
    " - Which movie has received the most ratings?\n",
    " - What is the average rating for the movie 'Star Wars'?\n",
    " - What is the occupation and age of the user that has given the most ratings?\n",
    " \n",
    "You will need to use the MongoDB aggregation framework to answer these questions (perhaps combined with client side code). The new aggregation framework offers the most flexibility and performance. Before starting the exercise look at the worked examples in the [documentation](http://api.mongodb.com/python/current/examples/aggregation.html).\n",
    "\n",
    "__Extra__: Based on the queries above, and the general structure of the database, can you identify any columns that will need indexes? Does the data model you chose impact the way you structure your queries? Does it impact any client side processing?\n",
    "\n",
    "Finally if you have time and you want to practice some more advanced queries, try answering the following\n",
    "questions:\n",
    "\n",
    " - How many different genres does a movie have on average?\n",
    " - What is the male/female distribution over both the userbase and the ratings?\n",
    " - What is the most controversial movie (has the highest variance in its\n",
    "   ratings)?\n",
    "\n",
    "__Extra__: Plot the distributions using e.g. Matplotlib or Seaborn\n",
    "\n",
    "__Assignment:__ Try to answer at least the first three questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO implement your queries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
